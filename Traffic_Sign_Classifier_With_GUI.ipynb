{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is Traffic Signs Recognition?\n",
    "### There are several different types of traffic signs like speed limits, no entry, traffic signals, turn left or right, children crossing, no passing of heavy vehicles, etc. Traffic signs classification is the process of identifying which class a traffic sign belongs to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image # pillow librabry to apen image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential,load_model\n",
    "from sklearn.model_selection import train_test_split # TO SPLIT DATA into train,test and validation\n",
    "from keras.layers import Conv2D,MaxPool2D,Dense,Flatten,Dropout\n",
    "from keras.utils import to_categorical  # it is used to convert y into one hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For this project, we are using the public dataset available at Kaggle\n",
    "### The dataset contains more than 50,000 images of different traffic signs. It is further classified into 43 different classes. The dataset is quite varying, some of the classes have many images while some classes have few images. The size of the dataset is around 300 MB. The dataset has a train folder which contains images inside each class and a test folder which we will use for testing our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Abhay\\\\Desktop'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()\n",
    "# os is used to manipluate files iterate over the folder|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‘train’ folder contains 43 folders each representing a different class. The range of the folder is from 0 to 42. With the help of the OS module, we iterate over all the classes and append images and their respective labels in the data and labels list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((39209, 30, 30, 3), (39209,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(r'C:\\Users\\Abhay\\Desktop\\Traffic') # to change directory\n",
    "data=[]\n",
    "label=[]\n",
    "classes=43\n",
    "for i in range (classes):\n",
    "    path=os.path.join(os.getcwd(),'Train',str(i))\n",
    "    images=os.listdir(path)\n",
    "    \n",
    "    for a in images:\n",
    "        image=Image.open(path+'\\\\'+a)\n",
    "        image=image.resize((30,30))\n",
    "        image=np.array(image)\n",
    "        data.append(image)\n",
    "        label.append(i)\n",
    "        \n",
    "data=np.array(data)\n",
    "label=np.array(label)\n",
    "data.shape,label.shape\n",
    "# shape of image is(30,30,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0, ..., 42, 42, 42])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train shape (31367,)\n",
      "y_val shape (7842,)\n",
      "before hot encoding\n",
      "x_train shape (31367, 30, 30, 3)\n",
      "x_val shape (7842, 30, 30, 3)\n",
      "y_train shape (31367, 43)\n",
      "y_val shape (7842, 43)\n"
     ]
    }
   ],
   "source": [
    "x_train,x_val,y_train,y_val=train_test_split(data,label,test_size=0.2,random_state=42)\n",
    "print(\"y_train shape\",y_train.shape)\n",
    "print(\"y_val shape\",y_val.shape)\n",
    "print(\"before hot encoding\")\n",
    "y_train=to_categorical(y_train,43)\n",
    "y_val=to_categorical(y_val,43)\n",
    "print(\"x_train shape\", x_train.shape)\n",
    "print(\"x_val shape\" ,x_val.shape)\n",
    "print(\"y_train shape\", y_train.shape)\n",
    "print(\"y_val shape\", y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To classify the images into their respective categories, i will build a CNN model (Convolutional Neural Network). CNN is best for image classification purposes.\n",
    "\n",
    "### I compile the model with Adam optimizer which performs well and loss is “categorical_crossentropy” because we have multiple classes to categorise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Conv2D(filters=32, kernel_size=(5,5), activation='relu', input_shape=x_train.shape[1:]))\n",
    "model.add(Conv2D(filters=32, kernel_size=(5,5), activation='relu'))\n",
    "model.add(Conv2D(filters=32, kernel_size=(5,5), activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(rate=0.5))\n",
    "model.add(Dense(43, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "62/62 [==============================] - 61s 981ms/step - loss: 5.0937 - accuracy: 0.0867 - val_loss: 3.0004 - val_accuracy: 0.3647\n",
      "Epoch 2/15\n",
      "62/62 [==============================] - 54s 877ms/step - loss: 2.4940 - accuracy: 0.3664 - val_loss: 1.4923 - val_accuracy: 0.6507\n",
      "Epoch 3/15\n",
      "62/62 [==============================] - 56s 898ms/step - loss: 1.5655 - accuracy: 0.5670 - val_loss: 0.7900 - val_accuracy: 0.8206\n",
      "Epoch 4/15\n",
      "62/62 [==============================] - 55s 895ms/step - loss: 1.1093 - accuracy: 0.6865 - val_loss: 0.5049 - val_accuracy: 0.8795\n",
      "Epoch 5/15\n",
      "62/62 [==============================] - 58s 930ms/step - loss: 0.8084 - accuracy: 0.7672 - val_loss: 0.3598 - val_accuracy: 0.9251\n",
      "Epoch 6/15\n",
      "62/62 [==============================] - 57s 915ms/step - loss: 0.6309 - accuracy: 0.8158 - val_loss: 0.2747 - val_accuracy: 0.9333\n",
      "Epoch 7/15\n",
      "13/62 [=====>........................] - ETA: 41s - loss: 0.5703 - accuracy: 0.8361"
     ]
    }
   ],
   "source": [
    "epochs = 15\n",
    "history = model.fit(x_train, y_train, batch_size=512,epochs=epochs,verbose=1, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our model got a 95% accuracy on the training dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset contains a test folder and in a test.csv file, which have the details related to the image path and their respective class labels.Extract the image path and labels using pandas. Then to predict the model,I have to resize our images to 30×30 pixels and make a numpy array containing all image data. \n",
    "\n",
    "### From the sklearn.metrics, I imported the accuracy_score and observed how MY model predicted the actual labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=pd.read_csv(r\"C:\\Users\\Abhay\\Desktop\\Traffic\\Test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Width</th>\n",
       "      <th>Height</th>\n",
       "      <th>Roi.X1</th>\n",
       "      <th>Roi.Y1</th>\n",
       "      <th>Roi.X2</th>\n",
       "      <th>Roi.Y2</th>\n",
       "      <th>ClassId</th>\n",
       "      <th>Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>54</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>48</td>\n",
       "      <td>49</td>\n",
       "      <td>16</td>\n",
       "      <td>Test/00000.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>45</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>36</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>Test/00001.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>48</td>\n",
       "      <td>52</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>43</td>\n",
       "      <td>47</td>\n",
       "      <td>38</td>\n",
       "      <td>Test/00002.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>24</td>\n",
       "      <td>33</td>\n",
       "      <td>Test/00003.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>60</td>\n",
       "      <td>57</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>55</td>\n",
       "      <td>52</td>\n",
       "      <td>11</td>\n",
       "      <td>Test/00004.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12625</td>\n",
       "      <td>42</td>\n",
       "      <td>41</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>37</td>\n",
       "      <td>36</td>\n",
       "      <td>12</td>\n",
       "      <td>Test/12625.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12626</td>\n",
       "      <td>50</td>\n",
       "      <td>51</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>45</td>\n",
       "      <td>46</td>\n",
       "      <td>33</td>\n",
       "      <td>Test/12626.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12627</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>Test/12627.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12628</td>\n",
       "      <td>48</td>\n",
       "      <td>49</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>43</td>\n",
       "      <td>44</td>\n",
       "      <td>7</td>\n",
       "      <td>Test/12628.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12629</td>\n",
       "      <td>32</td>\n",
       "      <td>31</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>26</td>\n",
       "      <td>10</td>\n",
       "      <td>Test/12629.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12630 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Width  Height  Roi.X1  Roi.Y1  Roi.X2  Roi.Y2  ClassId            Path\n",
       "0         53      54       6       5      48      49       16  Test/00000.png\n",
       "1         42      45       5       5      36      40        1  Test/00001.png\n",
       "2         48      52       6       6      43      47       38  Test/00002.png\n",
       "3         27      29       5       5      22      24       33  Test/00003.png\n",
       "4         60      57       5       5      55      52       11  Test/00004.png\n",
       "...      ...     ...     ...     ...     ...     ...      ...             ...\n",
       "12625     42      41       5       6      37      36       12  Test/12625.png\n",
       "12626     50      51       6       5      45      46       33  Test/12626.png\n",
       "12627     29      29       6       6      24      24        6  Test/12627.png\n",
       "12628     48      49       5       6      43      44        7  Test/12628.png\n",
       "12629     32      31       6       5      27      26       10  Test/12629.png\n",
       "\n",
       "[12630 rows x 8 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "images=test['Path'].values ## path column contains the name of the image int test folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "images=test['Path'].values\n",
    "labels=test['ClassId'].values\n",
    "data2=[]\n",
    "for img in images:\n",
    "    image=Image.open(img)    \n",
    "    image=image.resize((30,30))\n",
    "    image=np.array(image)## conerting image to array\n",
    "    data2.append(image)\n",
    "x_test=np.array(data2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[115, 138, 173],\n",
       "         [116, 137, 169],\n",
       "         [119, 137, 172],\n",
       "         ...,\n",
       "         [ 89, 103, 130],\n",
       "         [ 86, 110, 135],\n",
       "         [ 63,  82, 105]],\n",
       "\n",
       "        [[116, 143, 177],\n",
       "         [115, 140, 174],\n",
       "         [117, 141, 174],\n",
       "         ...,\n",
       "         [118, 142, 176],\n",
       "         [120, 141, 173],\n",
       "         [120, 139, 171]],\n",
       "\n",
       "        [[118, 141, 173],\n",
       "         [117, 142, 175],\n",
       "         [113, 140, 172],\n",
       "         ...,\n",
       "         [120, 144, 180],\n",
       "         [122, 144, 179],\n",
       "         [118, 142, 177]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[117, 137, 167],\n",
       "         [114, 134, 163],\n",
       "         [118, 136, 164],\n",
       "         ...,\n",
       "         [116, 139, 171],\n",
       "         [116, 136, 169],\n",
       "         [119, 140, 173]],\n",
       "\n",
       "        [[116, 136, 167],\n",
       "         [114, 134, 168],\n",
       "         [113, 131, 164],\n",
       "         ...,\n",
       "         [112, 135, 167],\n",
       "         [117, 136, 165],\n",
       "         [114, 140, 168]],\n",
       "\n",
       "        [[112, 135, 168],\n",
       "         [110, 135, 165],\n",
       "         [124, 136, 165],\n",
       "         ...,\n",
       "         [116, 139, 167],\n",
       "         [118, 139, 168],\n",
       "         [115, 140, 172]]],\n",
       "\n",
       "\n",
       "       [[[ 55,  69,  61],\n",
       "         [ 91,  78,  61],\n",
       "         [ 91,  81,  64],\n",
       "         ...,\n",
       "         [ 80,  65,  68],\n",
       "         [ 70,  63,  67],\n",
       "         [ 73,  69,  69]],\n",
       "\n",
       "        [[ 54,  65,  56],\n",
       "         [101,  80,  62],\n",
       "         [ 94,  79,  61],\n",
       "         ...,\n",
       "         [ 74,  63,  64],\n",
       "         [ 93,  71,  73],\n",
       "         [ 85,  68,  68]],\n",
       "\n",
       "        [[ 51,  65,  56],\n",
       "         [ 97,  82,  65],\n",
       "         [ 95,  82,  64],\n",
       "         ...,\n",
       "         [ 71,  65,  65],\n",
       "         [ 78,  67,  69],\n",
       "         [ 79,  69,  70]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 43,  43,  40],\n",
       "         [ 82,  66,  56],\n",
       "         [ 79,  66,  56],\n",
       "         ...,\n",
       "         [ 66,  62,  62],\n",
       "         [ 76,  67,  66],\n",
       "         [ 75,  67,  69]],\n",
       "\n",
       "        [[ 44,  43,  41],\n",
       "         [ 82,  66,  59],\n",
       "         [ 77,  65,  57],\n",
       "         ...,\n",
       "         [ 59,  60,  61],\n",
       "         [ 65,  64,  64],\n",
       "         [ 73,  67,  67]],\n",
       "\n",
       "        [[ 46,  41,  41],\n",
       "         [ 82,  66,  60],\n",
       "         [ 78,  66,  57],\n",
       "         ...,\n",
       "         [ 61,  57,  60],\n",
       "         [ 70,  65,  70],\n",
       "         [ 75,  71,  71]]],\n",
       "\n",
       "\n",
       "       [[[ 50,  38,  36],\n",
       "         [ 49,  38,  37],\n",
       "         [ 49,  38,  37],\n",
       "         ...,\n",
       "         [ 53,  44,  47],\n",
       "         [ 54,  45,  48],\n",
       "         [ 55,  46,  49]],\n",
       "\n",
       "        [[ 59,  45,  42],\n",
       "         [ 59,  44,  41],\n",
       "         [ 56,  44,  41],\n",
       "         ...,\n",
       "         [ 53,  42,  42],\n",
       "         [ 54,  44,  45],\n",
       "         [ 56,  46,  45]],\n",
       "\n",
       "        [[ 70,  50,  46],\n",
       "         [ 67,  51,  47],\n",
       "         [ 68,  50,  46],\n",
       "         ...,\n",
       "         [ 61,  44,  41],\n",
       "         [ 59,  44,  41],\n",
       "         [ 60,  45,  42]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 28,  24,  26],\n",
       "         [ 28,  24,  26],\n",
       "         [ 29,  27,  28],\n",
       "         ...,\n",
       "         [ 27,  24,  25],\n",
       "         [ 27,  24,  23],\n",
       "         [ 26,  24,  24]],\n",
       "\n",
       "        [[ 30,  27,  28],\n",
       "         [ 38,  33,  35],\n",
       "         [ 42,  36,  39],\n",
       "         ...,\n",
       "         [ 33,  31,  28],\n",
       "         [ 40,  38,  36],\n",
       "         [ 47,  45,  45]],\n",
       "\n",
       "        [[ 29,  27,  28],\n",
       "         [ 31,  26,  26],\n",
       "         [ 51,  37,  34],\n",
       "         ...,\n",
       "         [ 42,  41,  40],\n",
       "         [ 44,  43,  44],\n",
       "         [ 47,  46,  43]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[ 24,  27,  34],\n",
       "         [ 23,  25,  32],\n",
       "         [ 24,  25,  32],\n",
       "         ...,\n",
       "         [ 26,  27,  33],\n",
       "         [ 26,  27,  34],\n",
       "         [ 26,  27,  34]],\n",
       "\n",
       "        [[ 25,  26,  33],\n",
       "         [ 25,  26,  34],\n",
       "         [ 26,  26,  33],\n",
       "         ...,\n",
       "         [ 26,  27,  34],\n",
       "         [ 27,  27,  35],\n",
       "         [ 28,  28,  36]],\n",
       "\n",
       "        [[ 26,  26,  32],\n",
       "         [ 25,  25,  32],\n",
       "         [ 24,  24,  30],\n",
       "         ...,\n",
       "         [ 26,  27,  33],\n",
       "         [ 27,  27,  33],\n",
       "         [ 27,  26,  33]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 16,  17,  21],\n",
       "         [ 15,  16,  21],\n",
       "         [ 14,  16,  21],\n",
       "         ...,\n",
       "         [ 19,  21,  29],\n",
       "         [ 21,  23,  33],\n",
       "         [ 19,  21,  30]],\n",
       "\n",
       "        [[ 16,  17,  22],\n",
       "         [ 15,  16,  21],\n",
       "         [ 14,  16,  21],\n",
       "         ...,\n",
       "         [ 19,  21,  30],\n",
       "         [ 20,  22,  32],\n",
       "         [ 19,  22,  32]],\n",
       "\n",
       "        [[ 15,  16,  21],\n",
       "         [ 15,  16,  21],\n",
       "         [ 14,  16,  21],\n",
       "         ...,\n",
       "         [ 18,  21,  30],\n",
       "         [ 19,  22,  32],\n",
       "         [ 18,  22,  31]]],\n",
       "\n",
       "\n",
       "       [[[ 47,  60,  74],\n",
       "         [ 53,  58,  72],\n",
       "         [ 53,  47,  47],\n",
       "         ...,\n",
       "         [ 37,  31,  37],\n",
       "         [ 13,  10,  12],\n",
       "         [ 10,   9,  12]],\n",
       "\n",
       "        [[ 63,  72,  88],\n",
       "         [ 66,  60,  75],\n",
       "         [ 51,  49,  52],\n",
       "         ...,\n",
       "         [ 22,  18,  23],\n",
       "         [ 13,  10,   7],\n",
       "         [ 11,   9,  11]],\n",
       "\n",
       "        [[ 64,  73,  90],\n",
       "         [ 67,  80, 100],\n",
       "         [ 67,  77,  91],\n",
       "         ...,\n",
       "         [ 42,  42,  41],\n",
       "         [ 36,  32,  25],\n",
       "         [ 14,   9,  12]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 20,  20,  23],\n",
       "         [ 18,  18,  21],\n",
       "         [ 16,  15,  20],\n",
       "         ...,\n",
       "         [ 39,  37,  43],\n",
       "         [ 39,  39,  49],\n",
       "         [ 19,  18,  18]],\n",
       "\n",
       "        [[ 13,  12,  15],\n",
       "         [ 13,  12,  14],\n",
       "         [ 12,  10,  13],\n",
       "         ...,\n",
       "         [ 27,  29,  34],\n",
       "         [ 32,  34,  40],\n",
       "         [ 26,  25,  21]],\n",
       "\n",
       "        [[ 12,  11,  14],\n",
       "         [ 12,  11,  13],\n",
       "         [ 12,  10,  12],\n",
       "         ...,\n",
       "         [ 29,  34,  42],\n",
       "         [ 36,  38,  42],\n",
       "         [ 27,  24,  18]]],\n",
       "\n",
       "\n",
       "       [[[ 10,  10,  13],\n",
       "         [ 10,  10,  13],\n",
       "         [ 10,   9,  12],\n",
       "         ...,\n",
       "         [ 13,  12,  15],\n",
       "         [ 13,  12,  15],\n",
       "         [ 13,  12,  16]],\n",
       "\n",
       "        [[ 12,  11,  14],\n",
       "         [  9,   9,  12],\n",
       "         [  9,   9,  12],\n",
       "         ...,\n",
       "         [ 13,  12,  14],\n",
       "         [ 13,  12,  15],\n",
       "         [ 13,  12,  16]],\n",
       "\n",
       "        [[ 11,   9,  11],\n",
       "         [  9,   8,  11],\n",
       "         [  9,   9,  12],\n",
       "         ...,\n",
       "         [ 13,  12,  14],\n",
       "         [ 13,  12,  15],\n",
       "         [ 13,  12,  16]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 11,   9,  13],\n",
       "         [ 10,   9,  12],\n",
       "         [ 11,  10,  13],\n",
       "         ...,\n",
       "         [ 11,  10,  13],\n",
       "         [ 10,   9,  12],\n",
       "         [ 12,  11,  14]],\n",
       "\n",
       "        [[ 11,  10,  14],\n",
       "         [ 11,  10,  14],\n",
       "         [ 11,  10,  14],\n",
       "         ...,\n",
       "         [  9,   9,  12],\n",
       "         [  9,   9,  11],\n",
       "         [ 12,  11,  13]],\n",
       "\n",
       "        [[ 10,  10,  13],\n",
       "         [ 10,   9,  12],\n",
       "         [ 11,   9,  12],\n",
       "         ...,\n",
       "         [ 10,  10,  13],\n",
       "         [  9,  10,  12],\n",
       "         [ 11,  11,  13]]]], dtype=uint8)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-15-a8976e85224c>:1: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
     ]
    }
   ],
   "source": [
    "y_predict=model.predict_classes(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9501979414093429"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(labels,y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model achieved a 96% accuracy in this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('classifier96.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traffic Signs Classifier GUI(Graphical User Interface)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import *\n",
    "import tkinter as tk\n",
    "from PIL import Image,ImageTk\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I build the GUI for uploading the image and a button is used to classify which calls the classify() function. The classify() function is converting the image into the dimension of shape (1, 30, 30, 3). This is because to predict the traffic sign we have to provide the same dimension which we have used when building the model. Then we predict the class, the model.predict_classes(image) returns us a number between (0-42) which represents the class it belongs to. I use the dictionary to get the information about the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import filedialog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = { 1:'Speed limit (20km/h)',\n",
    "            2:'Speed limit (30km/h)', \n",
    "            3:'Speed limit (50km/h)', \n",
    "            4:'Speed limit (60km/h)', \n",
    "            5:'Speed limit (70km/h)', \n",
    "            6:'Speed limit (80km/h)', \n",
    "            7:'End of speed limit (80km/h)', \n",
    "            8:'Speed limit (100km/h)', \n",
    "            9:'Speed limit (120km/h)', \n",
    "            10:'No passing', \n",
    "            11:'No passing veh over 3.5 tons', \n",
    "            12:'Right-of-way at intersection', \n",
    "            13:'Priority road', \n",
    "            14:'Yield', \n",
    "            15:'Stop', \n",
    "            16:'No vehicles', \n",
    "            17:'Veh > 3.5 tons prohibited', \n",
    "            18:'No entry', \n",
    "            19:'General caution', \n",
    "            20:'Dangerous curve left', \n",
    "            21:'Dangerous curve right', \n",
    "            22:'Double curve', \n",
    "            23:'Bumpy road', \n",
    "            24:'Slippery road', \n",
    "            25:'Road narrows on the right', \n",
    "            26:'Road work', \n",
    "            27:'Traffic signals', \n",
    "            28:'Pedestrians', \n",
    "            29:'Children crossing', \n",
    "            30:'Bicycles crossing', \n",
    "            31:'Beware of ice/snow',\n",
    "            32:'Wild animals crossing', \n",
    "            33:'End speed + passing limits', \n",
    "            34:'Turn right ahead', \n",
    "            35:'Turn left ahead', \n",
    "            36:'Ahead only', \n",
    "            37:'Go straight or right', \n",
    "            38:'Go straight or left', \n",
    "            39:'Keep right', \n",
    "            40:'Keep left', \n",
    "            41:'Roundabout mandatory', \n",
    "            42:'End of no passing', \n",
    "            43:'End no passing veh > 3.5 tons' }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root=tk.Tk()\n",
    "root.geometry('800x600')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "label=Label(root,background='yellow', font=('arial',15,'bold'))\n",
    "sign_image=Label(root)  #making label for image\n",
    "def classify(filepath):\n",
    "    global label_packed\n",
    "    image=Image.open(filepath)\n",
    "    image=image.resize((30,30))\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    image = np.array(image)\n",
    "    pred = model.predict_classes([image])[0]\n",
    "    sign = classes[pred+1]\n",
    "    print(sign)\n",
    "    label.configure(foreground='#011638', text=sign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_classify_button(file_path):\n",
    "    classify_b=Button(root,text=\"Classify Image\",command=lambda: classify(file_path),padx=10,pady=5)\n",
    "    classify_b.configure(background='#364156', foreground='white',font=('arial',10,'bold'))\n",
    "    classify_b.place(relx=0.79,rely=0.46)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_image():\n",
    "    try:\n",
    "        filepath=filedialog.askopenfilename()\n",
    "        upload=Image.open(filepath)\n",
    "        upload.thumbnail(((root.winfo_width()/2.25),(root.winfo_height()/2.25)))\n",
    "        im=ImageTk.PhotoImage(upload)\n",
    "\n",
    "            \n",
    "        sign_image.configure(image=im)\n",
    "        sign_image.image=im #taking a refrence\n",
    "        label.configure(text='')\n",
    "        show_classify_button(filepath)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Turn right ahead\n",
      "Turn left ahead\n",
      "General caution\n",
      "No passing\n",
      "Speed limit (80km/h)\n",
      "Yield\n",
      "Yield\n",
      "Speed limit (50km/h)\n",
      "Ahead only\n",
      "Ahead only\n",
      "Ahead only\n"
     ]
    }
   ],
   "source": [
    "# upload button\n",
    "upload=Button(root,text=\"Upload an image\",command=upload_image,padx=10,pady=5)\n",
    "upload.configure(background='#364156', foreground='white',font=('arial',10,'bold'))\n",
    "upload.pack(side=BOTTOM,pady=50)\n",
    "label.pack(side=BOTTOM,expand=True)\n",
    "sign_image.pack(side=BOTTOM,expand=True)\n",
    "heading = Label(root, text=\"Know Your Traffic Sign\",pady=20, font=('arial',20,'bold'))\n",
    "heading.configure(background='#CDCDCD',foreground='#364156')\n",
    "heading.pack()\n",
    "\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
